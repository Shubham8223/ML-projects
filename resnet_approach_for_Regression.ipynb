{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkBkTOwWYfhM",
        "outputId": "0293695b-a6e7-4038-d9df-5e30378d0e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 4s 89ms/step - loss: 2626.7109 - mae: 41.8689 - val_loss: 2105.4783 - val_mae: 44.2126\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 2017.7433 - mae: 43.4306 - val_loss: 2367.8362 - val_mae: 47.1017\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1967.6278 - mae: 42.8543 - val_loss: 1526.9498 - val_mae: 36.9835\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 722.0524 - mae: 23.1328 - val_loss: 1738.4054 - val_mae: 27.6301\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 828.3739 - mae: 23.1748 - val_loss: 1053.9930 - val_mae: 30.3802\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 742.6663 - mae: 25.0591 - val_loss: 411.3287 - val_mae: 17.4381\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 345.0975 - mae: 14.2831 - val_loss: 150.4778 - val_mae: 10.5450\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 209.1418 - mae: 11.7682 - val_loss: 349.1954 - val_mae: 15.7412\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 178.3596 - mae: 10.2550 - val_loss: 196.6875 - val_mae: 10.8554\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 165.4820 - mae: 10.1416 - val_loss: 165.3028 - val_mae: 9.9228\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 108.5063 - mae: 7.4030 - val_loss: 118.3735 - val_mae: 8.5808\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 111.7514 - mae: 7.8310 - val_loss: 81.9736 - val_mae: 6.6384\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 83.3870 - mae: 7.0059 - val_loss: 126.5986 - val_mae: 9.5591\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 67.5200 - mae: 5.9906 - val_loss: 75.7089 - val_mae: 6.3501\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 62.4588 - mae: 5.8025 - val_loss: 95.7139 - val_mae: 7.3982\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 63.1764 - mae: 5.7016 - val_loss: 91.9677 - val_mae: 7.3033\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 50.1408 - mae: 5.1814 - val_loss: 75.3042 - val_mae: 6.0893\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 45.9424 - mae: 4.7590 - val_loss: 88.1720 - val_mae: 7.5035\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 54.3722 - mae: 5.2189 - val_loss: 60.9645 - val_mae: 5.8038\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 42.2424 - mae: 4.3684 - val_loss: 61.8288 - val_mae: 5.9011\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 46.2025 - mae: 4.5537 - val_loss: 77.7879 - val_mae: 7.0275\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 42.1260 - mae: 4.3778 - val_loss: 64.7808 - val_mae: 6.2765\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 44.5553 - mae: 4.6414 - val_loss: 77.4394 - val_mae: 7.1075\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 55.2649 - mae: 5.4802 - val_loss: 58.7992 - val_mae: 6.1507\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 48.3294 - mae: 5.2537 - val_loss: 75.8763 - val_mae: 7.1237\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 27.9661 - mae: 3.4599 - val_loss: 54.6256 - val_mae: 5.7516\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 42.5125 - mae: 4.6721 - val_loss: 86.9644 - val_mae: 7.8154\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 34.0937 - mae: 4.3845 - val_loss: 50.2906 - val_mae: 5.4848\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 32.5733 - mae: 3.9021 - val_loss: 74.4350 - val_mae: 7.1408\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 45.1406 - mae: 5.3554 - val_loss: 54.8492 - val_mae: 5.9935\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 35.0316 - mae: 4.2515 - val_loss: 66.6842 - val_mae: 6.6763\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 38.6749 - mae: 4.6897 - val_loss: 66.8329 - val_mae: 6.5673\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 31.2603 - mae: 4.2599 - val_loss: 57.8430 - val_mae: 6.2035\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 30.8792 - mae: 4.2353 - val_loss: 65.8327 - val_mae: 6.7832\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 26.4730 - mae: 3.7684 - val_loss: 55.2043 - val_mae: 6.1372\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 22.2638 - mae: 3.7152 - val_loss: 66.7448 - val_mae: 6.6631\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 17.3404 - mae: 2.9344 - val_loss: 50.7766 - val_mae: 5.3026\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 12.9344 - mae: 2.4962 - val_loss: 73.5900 - val_mae: 7.2405\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 15.8934 - mae: 3.0870 - val_loss: 53.6589 - val_mae: 5.3731\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 15.2709 - mae: 2.9504 - val_loss: 72.4888 - val_mae: 7.0499\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 15.7189 - mae: 2.7319 - val_loss: 49.8316 - val_mae: 5.6365\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 15.1513 - mae: 2.7311 - val_loss: 61.0681 - val_mae: 6.4541\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 14.1438 - mae: 2.7968 - val_loss: 48.7026 - val_mae: 5.4189\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 10.5691 - mae: 2.1886 - val_loss: 59.6409 - val_mae: 6.4917\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 11.8771 - mae: 2.2322 - val_loss: 51.8467 - val_mae: 5.8415\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 10.3570 - mae: 2.2185 - val_loss: 60.8816 - val_mae: 6.4004\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 11.4400 - mae: 2.2205 - val_loss: 61.0608 - val_mae: 6.4739\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 10.7005 - mae: 2.2404 - val_loss: 57.3104 - val_mae: 6.0723\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 12.5164 - mae: 2.5228 - val_loss: 65.6073 - val_mae: 6.7798\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 12.6126 - mae: 2.6742 - val_loss: 49.8719 - val_mae: 5.5072\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 12.8263 - mae: 2.7467 - val_loss: 69.4922 - val_mae: 7.0632\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 12.9516 - mae: 2.7323 - val_loss: 54.1342 - val_mae: 5.5455\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 13.5550 - mae: 2.6116 - val_loss: 65.9697 - val_mae: 6.7961\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 10.5402 - mae: 2.2139 - val_loss: 50.3674 - val_mae: 5.4037\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 14.4727 - mae: 2.7881 - val_loss: 63.8898 - val_mae: 6.7289\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 16.3842 - mae: 2.9942 - val_loss: 51.7299 - val_mae: 5.8717\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 13.3572 - mae: 2.7820 - val_loss: 59.3893 - val_mae: 6.2198\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 16.6953 - mae: 3.0095 - val_loss: 76.8838 - val_mae: 7.4560\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 20.8262 - mae: 3.6703 - val_loss: 56.3560 - val_mae: 5.5554\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 20.8228 - mae: 3.6487 - val_loss: 64.9081 - val_mae: 6.7056\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 15.8375 - mae: 2.8451 - val_loss: 54.7575 - val_mae: 6.0419\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 24.3386 - mae: 3.7863 - val_loss: 64.8104 - val_mae: 6.8942\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 26.3483 - mae: 4.1589 - val_loss: 66.5353 - val_mae: 6.9171\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 28.9299 - mae: 4.1925 - val_loss: 63.1613 - val_mae: 6.1777\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 26.0422 - mae: 3.8509 - val_loss: 91.2279 - val_mae: 8.0981\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 23.1255 - mae: 3.8588 - val_loss: 96.5002 - val_mae: 7.2842\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 29.0581 - mae: 4.3853 - val_loss: 112.5495 - val_mae: 9.1117\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 32.8464 - mae: 4.9020 - val_loss: 70.0586 - val_mae: 6.1994\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 40.7546 - mae: 4.9509 - val_loss: 110.8555 - val_mae: 8.9993\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 23.1354 - mae: 3.8658 - val_loss: 70.8240 - val_mae: 6.3492\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 27.7388 - mae: 4.3367 - val_loss: 114.0948 - val_mae: 9.1240\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 27.8711 - mae: 4.2352 - val_loss: 52.9051 - val_mae: 5.8738\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 21.4391 - mae: 3.3998 - val_loss: 85.3057 - val_mae: 7.6911\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 19.1401 - mae: 3.2823 - val_loss: 47.1460 - val_mae: 5.2480\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 14.1471 - mae: 2.8537 - val_loss: 70.4216 - val_mae: 7.0777\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 14.0290 - mae: 2.7355 - val_loss: 47.6230 - val_mae: 5.2897\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 14.8641 - mae: 2.7932 - val_loss: 63.6426 - val_mae: 6.6114\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 13.5416 - mae: 2.4820 - val_loss: 62.8318 - val_mae: 6.3887\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 18.1340 - mae: 3.2527 - val_loss: 54.5359 - val_mae: 5.6488\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 18.2693 - mae: 3.1710 - val_loss: 80.1731 - val_mae: 7.7627\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 18.6741 - mae: 3.4430 - val_loss: 43.8642 - val_mae: 5.0006\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 13.0767 - mae: 2.6981 - val_loss: 62.2471 - val_mae: 6.8238\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 10.2713 - mae: 2.1835 - val_loss: 43.2249 - val_mae: 5.0446\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 9.5943 - mae: 2.1464 - val_loss: 57.4917 - val_mae: 6.3623\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 7.5075 - mae: 1.7801 - val_loss: 52.3902 - val_mae: 5.3303\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 8.8004 - mae: 2.0811 - val_loss: 65.7758 - val_mae: 6.8215\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 7.7927 - mae: 1.8830 - val_loss: 50.6152 - val_mae: 5.5582\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 9.6910 - mae: 2.1245 - val_loss: 59.5096 - val_mae: 6.4545\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 10.1839 - mae: 2.1133 - val_loss: 53.7426 - val_mae: 5.8020\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 8.4573 - mae: 1.8346 - val_loss: 55.0569 - val_mae: 6.0632\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 7.9297 - mae: 1.6884 - val_loss: 54.0842 - val_mae: 5.9075\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 6.6021 - mae: 1.5126 - val_loss: 52.0108 - val_mae: 5.7771\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 6.9470 - mae: 1.4983 - val_loss: 54.1226 - val_mae: 5.9956\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 6.5786 - mae: 1.3898 - val_loss: 55.6833 - val_mae: 6.1922\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 7.4738 - mae: 1.7157 - val_loss: 47.7302 - val_mae: 5.2125\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 12.8614 - mae: 2.8360 - val_loss: 75.7603 - val_mae: 7.3958\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 11.1217 - mae: 2.6650 - val_loss: 44.5105 - val_mae: 5.2724\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 11.1157 - mae: 2.5685 - val_loss: 80.1726 - val_mae: 7.5299\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 12.4251 - mae: 2.7414 - val_loss: 49.0455 - val_mae: 5.0586\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 12.8363 - mae: 2.6939 - val_loss: 84.1390 - val_mae: 7.8779\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/merged_oil_data.csv')\n",
        "features = data[['Palmitic Acid (%)', 'Stearic Acid (%)', 'Oleic Acid (%)', 'Linoleic Acid (%)', 'Linolenic Acid (%)', 'Erucic Acid (%)']]\n",
        "targets = data[['Pour Point', 'Cloud Point', 'Flash Point', 'Fire Point', 'Viscosity (cSt)', 'Density (g/cm3)', 'Cetane Number', 'HHV (MJ/kg)']]\n",
        "\n",
        "# Split and standardize the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, targets, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "\n",
        "# Define the deep recurrent model\n",
        "inputs = layers.Input(shape=(6,))\n",
        "x = layers.Dense(64, activation='relu')(inputs)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(128*2, activation='relu')(x)\n",
        "x = layers.Dense(128*4, activation='relu')(x)\n",
        "x3 = layers.Dense(128*8, activation='relu')(x)\n",
        "x4 = layers.Dense(128*16, activation='relu')(x3)\n",
        "x5 = layers.Dense(128*32, activation='relu')(x4)\n",
        "x6 = layers.Dense(128*64, activation='relu')(x5)\n",
        "x = layers.Dense(128*32, activation='relu')(x6)\n",
        "x=layers.Add()([x,x5])\n",
        "outputs = layers.Dense(1, activation='linear')(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])\n",
        "history = model.fit(X_train, y_train['Viscosity (cSt)'], validation_data=(X_val, y_val['Viscosity (cSt)']), epochs=100, batch_size=16)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_train)\n",
        "r2_scores = r2_score(y_train['Viscosity (cSt)'], y_pred)\n",
        "print(r2_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whrs-bb0eMAp",
        "outputId": "408f2769-b893-4cd4-da37-7ce950015384"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n",
            "0.88219773091346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in zip(y_pred,y_train['Viscosity (cSt)']):\n",
        "  print(i,j)"
      ],
      "metadata": {
        "id": "ikeUGmUcLaCJ",
        "outputId": "0e763348-fa9f-49a0-dd85-8090b3c6962e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[37.936054] 40\n",
            "[33.341022] 35\n",
            "[36.347195] 40\n",
            "[47.039158] 50\n",
            "[39.396122] 40\n",
            "[41.275833] 45\n",
            "[43.558273] 45\n",
            "[38.09519] 40\n",
            "[37.20979] 40\n",
            "[41.911007] 45\n",
            "[58.39819] 65\n",
            "[41.896618] 47\n",
            "[44.50764] 45\n",
            "[37.721878] 40\n",
            "[33.613064] 45\n",
            "[49.159824] 50\n",
            "[31.192682] 25\n",
            "[47.463264] 55\n",
            "[43.031883] 45\n",
            "[43.726406] 45\n",
            "[44.25754] 50\n",
            "[90.174805] 100\n",
            "[43.43984] 45\n",
            "[27.972069] 30\n",
            "[46.006298] 50\n",
            "[32.285976] 35\n",
            "[48.59193] 50\n",
            "[32.400726] 30\n",
            "[23.826202] 25\n",
            "[56.508316] 60\n",
            "[44.388905] 45\n",
            "[42.21692] 45\n",
            "[66.39295] 70\n",
            "[40.85345] 40\n",
            "[66.19329] 70\n",
            "[41.311943] 45\n",
            "[38.297924] 40\n",
            "[41.311943] 45\n",
            "[57.77766] 60\n",
            "[43.726406] 45\n",
            "[35.720028] 45\n",
            "[48.841022] 55\n",
            "[43.088917] 45\n",
            "[34.17606] 30\n",
            "[32.303936] 35\n",
            "[39.455368] 45\n",
            "[45.971184] 50\n",
            "[37.939724] 40\n",
            "[48.050213] 50\n",
            "[46.35928] 50\n",
            "[30.644556] 32\n",
            "[43.117188] 45\n",
            "[32.264824] 35\n",
            "[34.30998] 35\n",
            "[33.678204] 35\n",
            "[42.568863] 45\n",
            "[44.55911] 45\n",
            "[37.50201] 40\n",
            "[35.02754] 40\n",
            "[37.99766] 45\n"
          ]
        }
      ]
    }
  ]
}